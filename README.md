# ImageCaptioning
Image Captioning is the process of generating textual description of an image. It uses both Natural Language Processing and Computer Vision to generate the captions. The dataset will be in the form [image to captions]. The dataset consists of input images and their corresponding output captions. The Convolutional Neural Network can be thought of as an encoder. The input image is given to CNN to extract the features from that image. The last hidden state of the CNN is connected to the Decoder as Recurrent Neural Network(RNN) which does language modelling up to the word level. The first time step receives the encoded output from the encoder along with START vector using Pretrained Resnet-50 model that is trained on ImageNet dataset (available publicly on google) for image feature extraction and created 4 layered RNN model and other relevant layers for image caption generation
